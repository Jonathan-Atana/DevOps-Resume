name: Build, Push, Scan and Deploy Image

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

permissions:
  id-token: write # Required to use OIDC
  contents: read # To clone the repo
  pull-requests: write # To post comments on PRs

env:
  AWS_REGION: us-east-1
  AWS_ROLE: ${{ secrets.AWS_ACTION_ROLE }}
  ECR_REPO_NAME: dev

jobs:
  build-push:
    runs-on: ubuntu-latest

    steps:
      # Check-out the repository
      - name: Checkout code (Clone Repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # ← This gets full history instead of shallow clone

      # Configure AWS Credentials using OIDC
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_ROLE }} # OIDC Role ARN
          aws-region: ${{ env.AWS_REGION }}

      # Log-in to Amazon ECR
      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v1
        with:
          mask-password: "true"

      # Scan code for secret leaks
      - name: Scan code for Secret Leaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # ← Needed for PRs

      # Convert sarif file exposed by gitleaks to json
      - name: Convert SARIF to Gitleaks JSON format
        if: always()
        run: |
          echo "🔄 Converting results.sarif to JSON format..."

          # Install jq
          sudo apt-get install -y jq

          if [ -f "results.sarif" ]; then
            # Check if there are actual results or just rule definitions
            RESULTS_COUNT=$(jq '.runs[0].results | length' results.sarif 2>/dev/null || echo "0")
            
            if [ "$RESULTS_COUNT" -gt 0 ]; then
              echo "✅ Gitleaks found $RESULTS_COUNT secrets - converting to JSON..."
              jq '
              .runs[0].results | map({
                RuleID: .ruleId,
                Description: (.message.text // .ruleId),
                File: (.locations[0].physicalLocation.artifactLocation.uri // "unknown"),
                StartLine: (.locations[0].physicalLocation.region.startLine // 0),
                EndLine: (.locations[0].physicalLocation.region.endLine // 0),
                Secret: (.properties.secret // "hidden"),
                Confidence: (.properties.confidence // "medium")
              })
              ' results.sarif > gitleaks-report.json
            else
              echo "✅ Gitleaks found no secrets - creating empty report"
              echo "[]" > gitleaks-report.json
            fi
            
            echo "📊 Findings count: $(jq '. | length' gitleaks-report.json)"
            
          else
            echo "❌ results.sarif not found - creating empty report"
            echo "[]" > gitleaks-report.json
          fi

      # Scan filesystem for vulnerabilities
      - name: Trivy filesystem vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "json"
          output: "trivy-fs-report.json"
          exit-code: "0" # Don't fail the build yet, we'll handle in comment
          ignore-unfixed: true
          vuln-type: "os,library"
          severity: "CRITICAL,HIGH,MEDIUM" # Include medium for better context

      # Build, and Tag Image
      - name: Build, and Tag Image
        run: |
          docker build -t ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }} .

      # Scan Image for Vulnerabilities
      - name: Trivy image vulnerability scanner
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }}
          format: "json"
          output: "trivy-image-report.json"
          exit-code: "0" # Don't fail the build yet, we'll handle in comment
          severity: "CRITICAL,HIGH,MEDIUM" # Include medium for better context

      # Push Image to Amazon ECR
      - name: Push Image to Amazon ECR
        # Only push to ECR on main branch commits (not PRs)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          docker push ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }}

      # Save image uri to a file
      - name: Save image URI to file
        # Only save image URI on main branch
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          echo "${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }}" > image_uri.txt

      # Upload image uri artifact
      - name: Upload image URI artifact
        # Only upload artifact on main branch
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: image-uri
          path: image_uri.txt

      # Post scan result in PRs comments
      - name: Post comprehensive security scan results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          script: |
            const { readFileSync, existsSync, statSync } = require('fs');

            // Debug: List all files in current directory
            console.log('📁 Current directory files:');
            require('child_process').execSync('ls -la', { stdio: 'inherit' });

            // Debug: Check each report file
            const reportFiles = ['gitleaks-report.json', 'trivy-fs-report.json', 'trivy-image-report.json'];

            reportFiles.forEach(file => {
              if (existsSync(file)) {
                const stats = statSync(file);
                console.log(`✅ ${file}: exists (${stats.size} bytes)`);
                try {
                  const content = readFileSync(file, 'utf8');
                  if (content.trim() === '') {
                    console.log(`❌ ${file}: exists but is EMPTY`);
                  } else {
                    console.log(`📊 ${file}: has content`);
                    // Quick peek at content
                    try {
                      const data = JSON.parse(content);
                      console.log(`   Structure: ${JSON.stringify(Object.keys(data)).slice(0, 100)}...`);
                    } catch (e) {
                      console.log(`   ❌ Invalid JSON: ${e.message}`);
                    }
                  }
                } catch (e) {
                  console.log(`❌ Error reading ${file}: ${e.message}`);
                }
              } else {
                console.log(`❌ ${file}: does NOT exist`);
              }
            });

            let comment = '## 🔍 Security Scan Results\n\n';
            let hasFindings = false;
            let totalFindings = 0;

            // Helper function to check if file exists and has content
            const checkFile = (filename) => {
              if (!existsSync(filename)) {
                console.log(`❌ ${filename} not found`);
                return null;
              }
              
              try {
                const content = readFileSync(filename, 'utf8');
                if (content.trim() === '') {
                  console.log(`❌ ${filename} is empty`);
                  return null;
                }
                
                return JSON.parse(content);
              } catch (e) {
                console.log(`❌ Error parsing ${filename}: ${e.message}`);
                return null;
              }
            };

            // Process Gitleaks results
            const gitleaksData = checkFile('gitleaks-report.json');
            if (gitleaksData) {
              console.log(`📊 Gitleaks data type: ${Array.isArray(gitleaksData) ? 'Array' : typeof gitleaksData}`);
              console.log(`📊 Gitleaks data keys: ${Object.keys(gitleaksData).join(', ')}`);
              
              // Handle different Gitleaks output formats
              const findings = Array.isArray(gitleaksData) ? gitleaksData : (gitleaksData.findings || []);
              
              if (findings.length > 0) {
                hasFindings = true;
                totalFindings += findings.length;
                comment += `### ⚠️ Secret Detection (Gitleaks) - ${findings.length} finding(s)\n`;
                
                findings.slice(0, 3).forEach(finding => {
                  const fileLink = `https://github.com/${context.repo.owner}/${context.repo.repo}/blob/${context.sha}/${finding.File}#L${finding.StartLine}`;
                  comment += `- **${finding.Description || finding.RuleID}** in [${finding.File}:${finding.StartLine}](${fileLink})\n`;
                });
                
                if (findings.length > 3) {
                  comment += `- ...and ${findings.length - 3} more\n`;
                }
                comment += '\n**Recommendation**: Remove these secrets and use GitHub Secrets or AWS Secrets Manager\n\n';
              } else {
                console.log('✅ Gitleaks: No findings (empty array)');
              }
            }

            // Process Trivy Filesystem results
            const trivyFsData = checkFile('trivy-fs-report.json');
            if (trivyFsData) {
              console.log('📊 Trivy FS data structure:', Object.keys(trivyFsData));
              // ... rest of your Trivy processing code
            }

            // Process Trivy Image results  
            const trivyImageData = checkFile('trivy-image-report.json');
            if (trivyImageData) {
              console.log('📊 Trivy Image data structure:', Object.keys(trivyImageData));
              // ... rest of your Trivy processing code
            }

            // If no findings from any scanner
            if (!hasFindings) {
              comment += '### ✅ All Security Scans Passed\n';
              comment += 'No security issues found in:\n';
              comment += '- Secret detection (Gitleaks) ✅\n';
              comment += '- Filesystem vulnerabilities (Trivy) ✅\n';
              comment += '- Container image vulnerabilities (Trivy) ✅\n\n';
              comment += 'Great job maintaining security best practices! 🎉\n';
            }

            // Post the comment
            try {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
              console.log('✅ Security scan results posted to PR');
            } catch (error) {
              console.log('❌ Error posting comment:', error.message);
            }

      # Cleanup
      - name: Cleanup local files
        if: always()
        run: rm -f image_uri.txt *.json *.sarif

  terraform-deploy:
    runs-on: ubuntu-latest
    needs: build-push
    # ONLY run on main branch pushes
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    env:
      TF_VERSION: "1.12.1"
      WORKING_DIR: "./infrastructure"

    steps:
      # Check-out the repository
      - name: Checkout code (Clone Repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # ← This gets full history instead of shallow clone

      # Terraform setup
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      # Configure AWS Credentials using OIDC
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_ROLE }} # OIDC Role ARN
          aws-region: ${{ env.AWS_REGION }}

      # Download plugins
      - name: Terraform Init
        run: terraform init -backend-config="bucket=${{ secrets.BUCKET_NAME }}"
        working-directory: ${{ env.WORKING_DIR }}

      # Terraform format and validate
      - name: Format, and validate config files
        run: terraform fmt && terraform validate
        working-directory: ${{ env.WORKING_DIR }}

      # Download image uri from artifact
      - name: Download image URI artifact
        uses: actions/download-artifact@v4
        with:
          name: image-uri

      # Read image uri and store in output
      - name: Read image URI
        id: read-image
        run: |
          echo "image_uri=$(cat image_uri.txt)" >> $GITHUB_OUTPUT

      # Terraform Plan
      - name: Plan of what is to be created
        env:
          TF_VAR_container_image: ${{ steps.read-image.outputs.image_uri }}
          TF_VAR_container_name: ${{ env.ECR_REPO_NAME }}
        run: terraform plan -out=tfplan
        working-directory: ${{ env.WORKING_DIR }}

      # Apply the plan
      - name: Apply configurations
        env:
          TF_VAR_container_image: ${{ steps.read-image.outputs.image_uri }}
          TF_VAR_container_name: ${{ env.ECR_REPO_NAME }}
        run: terraform apply -auto-approve tfplan
        working-directory: ${{ env.WORKING_DIR }}

      # Save file
      - name: Save Terraform outputs to file
        id: terraform-outputs
        run: |
          # Remove the first line (always the command) and save clean JSON
          terraform output -json 2>&1 | sed '1d' > all-outputs.json

          echo "✅ Terraform outputs saved to file"
        working-directory: ${{ env.WORKING_DIR }}

      # Upload to artifact
      - name: Upload Terraform outputs as artifact
        uses: actions/upload-artifact@v4
        with:
          name: all-outputs
          path: ${{ env.WORKING_DIR }}/all-outputs.json
          retention-days: 1

      # Cleanup
      - name: Cleanup local files
        if: always()
        run: |
          rm -f image_uri.txt
          rm -f all-outputs.json
          echo "✅ Local files cleaned up"

  verify-deployment:
    runs-on: ubuntu-latest
    needs: [terraform-deploy, build-push]
    # ONLY run on main branch pushes
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      # Check-out the repository
      - name: Checkout code (Clone Repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # ← This gets full history instead of shallow clone

      # Configure AWS Credentials using OIDC
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_ROLE }} # OIDC Role ARN
          aws-region: ${{ env.AWS_REGION }}

      # Download json file from artifact
      - name: Download Terraform outputs artifact
        uses: actions/download-artifact@v4
        with:
          name: all-outputs
          path: terraform-outputs/

      # Read artifacts and store in output
      - name: Parse JSON outputs
        id: parse-outputs
        run: |
          # Install jq if not already available
          sudo apt-get install -y jq

          # Check if file exists first
          if [ ! -f "terraform-outputs/all-outputs.json" ]; then
            echo "WARNING: all-outputs.json not found"
            echo "cluster_name=" >> $GITHUB_OUTPUT
            echo "service_name=" >> $GITHUB_OUTPUT
            echo "lb_dns=" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Then parse the file
          echo "cluster_name=$(jq -r '.["cluster-name"].value // empty' terraform-outputs/all-outputs.json)" >> $GITHUB_OUTPUT
          echo "service_name=$(jq -r '.["service-name"].value // empty' terraform-outputs/all-outputs.json)" >> $GITHUB_OUTPUT
          echo "lb_dns=$(jq -r '.["lb-dns"].value // empty' terraform-outputs/all-outputs.json)" >> $GITHUB_OUTPUT

      # Display info about deployment
      - name: Display deployment info
        run: |
          if [ -z "${{ steps.parse-outputs.outputs.cluster_name }}" ]; then
            echo "⚠️  No cluster information available"
          else
            echo "🚀 Deployment completed successfully!"
            echo "🏗️ Cluster: ${{ steps.parse-outputs.outputs.cluster_name }}"
            echo "🔧 Service: ${{ steps.parse-outputs.outputs.service_name }}"
            echo "🌐 Load Balancer DNS: ${{ steps.parse-outputs.outputs.lb_dns }}"
            echo "🔗 Service URL: http://${{ steps.parse-outputs.outputs.lb_dns }}"
          fi

      # Wait for ECS service to stabilize
      - name: Wait for service stability/healthiness
        timeout-minutes: 8 # ← Prevent hanging
        run: |
          aws ecs wait services-stable \
            --cluster ${{ steps.parse-outputs.outputs.cluster_name }} \
            --services ${{ steps.parse-outputs.outputs.service_name }} \
            || echo "⚠️ Service stabilization timeout or failed"
          echo "✅ Service is stable and healthy"

      # Test the load balancer endpoint
      - name: Test the ALB endpoint
        run: |
          curl -s -o /dev/null -w "HTTP Status: %{http_code}\n" http://${{ steps.parse-outputs.outputs.lb_dns }} || echo "Load balancer not ready yet"

      # Cleanup
      - name: Cleanup downloaded artifacts
        if: always()
        run: |
          rm -rf terraform-outputs/
          echo "✅ Downloaded artifacts cleaned up"
