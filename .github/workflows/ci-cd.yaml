name: Build, Push, Scan and Deploy Image

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

permissions:
  id-token: write # Required to use OIDC
  contents: read # To clone the repo

env:
  AWS_REGION: us-east-1
  AWS_ROLE: ${{ secrets.AWS_ACTION_ROLE }}
  ECR_REPO_NAME: dev

jobs:
  build-push:
    runs-on: ubuntu-latest

    steps:
      # Check-out the repository
      - name: Checkout code (Clone Repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # â† This gets full history instead of shallow clone

      # Configure AWS Credentials using OIDC
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_ROLE }} # OIDC Role ARN
          aws-region: ${{ env.AWS_REGION }}

      # Log-in to Amazon ECR
      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v1

      # Scan code for secret leaks
      - name: Scan code for Secret Leaks
        uses: gitleaks/gitleaks-action@v2

      # Scan filesystem for vulnerabilities
      - name: Trivy filesystem vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "table"
          exit-code: "1"
          ignore-unfixed: true
          vuln-type: "os,library"
          severity: "CRITICAL,HIGH"

      # Build, and Tag Image
      - name: Build, and Tag Image
        run: |
          docker build -t ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }} .

      # Scan Image for Vulnerabilities
      - name: Trivy image vulnerability scanner
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }}
          format: "table"
          exit-code: "1"
          severity: "CRITICAL,HIGH"

      # Push Image to Amazon ECR
      - name: Push Image to Amazon ECR
        run: |
          docker push ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }}

      # Save image uri to a file
      - name: Save image URI to file
        run: |
          echo "${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO_NAME }}:${{ github.run_number }}" > image_uri.txt

      # Upload image uri artifact
      - name: Upload image URI artifact
        uses: actions/upload-artifact@v4
        with:
          name: image-uri
          path: image_uri.txt

  terraform-deploy:
    runs-on: ubuntu-latest
    needs: build-push

    env:
      TF_VERSION: "1.12.1"
      WORKING_DIR: "./infrastructure"

    steps:
      # Check-out the repository
      - name: Checkout code (Clone Repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # â† This gets full history instead of shallow clone

      # Terraform setup
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      # Configure AWS Credentials using OIDC
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_ROLE }} # OIDC Role ARN
          aws-region: ${{ env.AWS_REGION }}

      # Download plugins
      - name: Terraform Init
        run: terraform init -backend-config="bucket=${{ secrets.BUCKET_NAME }}"
        working-directory: ${{ env.WORKING_DIR }}

      # Terraform format and validate
      - name: Format, and validate config files
        run: terraform fmt && terraform validate
        working-directory: ${{ env.WORKING_DIR }}

      # Download image uri from artifact
      - name: Download image URI artifact
        uses: actions/download-artifact@v4
        with:
          name: image-uri

      # Read image uri and store in output
      - name: Read image URI
        id: read-image
        run: |
          echo "image_uri=$(cat image_uri.txt)" >> $GITHUB_OUTPUT

      # Terraform Plan
      - name: Plan of what is to be created
        env:
          TF_VAR_container_image: ${{ steps.read-image.outputs.image_uri }}
          TF_VAR_container_name: ${{ env.ECR_REPO_NAME }}
        run: terraform plan -out=tfplan
        working-directory: ${{ env.WORKING_DIR }}

      # Apply the plan
      - name: Apply configurations
        env:
          TF_VAR_container_image: ${{ steps.read-image.outputs.image_uri }}
          TF_VAR_container_name: ${{ env.ECR_REPO_NAME }}
        run: terraform apply -auto-approve tfplan
        working-directory: ${{ env.WORKING_DIR }}

      # Save file
      - name: Extract Terraform outputs to file
        id: terraform-outputs
        run: |
          # Create a combined JSON file
          terraform output -json > all-outputs.json

          echo "âœ… Terraform outputs saved to file"
        working-directory: ${{ env.WORKING_DIR }}

      # Upload to artifact
      - name: Upload Terraform outputs as artifact
        uses: actions/upload-artifact@v4
        with:
          name: all-outputs
          path: ${{ env.WORKING_DIR }}/all-outputs.json
          retention-days: 1

  verify-deployment:
    runs-on: ubuntu-latest
    needs: [terraform-deploy, build-push]

    steps:
      # Check-out the repository
      - name: Checkout code (Clone Repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # â† This gets full history instead of shallow clone

      # Configure AWS Credentials using OIDC
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_ROLE }} # OIDC Role ARN
          aws-region: ${{ env.AWS_REGION }}

      # Download json file from artifact
      - name: Download Terraform outputs artifact
        uses: actions/download-artifact@v4
        with:
          name: all-outputs
          path: terraform-outputs/

      # Read artifacts and store in output
      - name: Parse JSON outputs
        id: parse-outputs
        run: |
          # Install jq if not already available
          sudo apt-get install -y jq

          # Check if file exists first
          if [ ! -f "terraform-outputs/all-outputs.json" ]; then
            echo "WARNING: all-outputs.json not found"
            echo "cluster_name=" >> $GITHUB_OUTPUT
            echo "service_name=" >> $GITHUB_OUTPUT
            echo "lb_dns=" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Then parse the file
          echo "cluster_name=$(jq -r '.["cluster-name"].value // empty' terraform-outputs/all-outputs.json)" >> $GITHUB_OUTPUT
          echo "service_name=$(jq -r '.["service-name"].value // empty' terraform-outputs/all-outputs.json)" >> $GITHUB_OUTPUT
          echo "lb_dns=$(jq -r '.["lb-dns"].value // empty' terraform-outputs/all-outputs.json)" >> $GITHUB_OUTPUT

      # Display info about deployment
      - name: Display deployment info
        run: |
          echo "ğŸš€ Deployment completed successfully!"
          echo "ğŸ—ï¸ Cluster: ${{ steps.parse-outputs.outputs.cluster_name }}"
          echo "ğŸ”§ Service: ${{ steps.parse-outputs.outputs.service_name }}"
          echo "ğŸŒ Load Balancer DNS: ${{ steps.parse-outputs.outputs.lb_dns }}"
          echo "ğŸ”— Service URL: http://${{ steps.parse-outputs.outputs.lb_dns }}"

      # Wait for ECS service to stabilize
      - name: Wait for service stability/healthiness
        timeout-minutes: 8 # â† Prevent hanging
        run: |
          aws ecs wait services-stable \
            --cluster ${{ steps.parse-outputs.outputs.cluster_name }} \
            --services ${{ steps.parse-outputs.outputs.service_name }} \
            || echo "âš ï¸ Service stabilization timeout or failed"
          echo "âœ… Service is stable and healthy"

      # Test the load balancer endpoint
      - name: Test the ALB endpoint
        run: |
          curl -s -o /dev/null -w "HTTP Status: %{http_code}\n" http://${{ steps.parse-outputs.outputs.lb_dns }} || echo "Load balancer not ready yet"
